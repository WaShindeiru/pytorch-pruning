{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Transfer Learning](./transfer_learning.jpg \"Transfer Learning\")",
   "id": "8bc768f58c0bf7fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![VGG16](./vgg16.webp \"VGG16\")",
   "id": "8169b86b9b81de88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![VGG16](./vgg16_2.webp \"VGG16\")",
   "id": "6f369a2a74fd5c12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import dataset\n",
    "from finetune import ModifiedVGG16Model"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "a12b9e92940828e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:51:16.488138Z",
     "start_time": "2025-05-11T07:51:16.483573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model_, test_loader_, device_, threshold=None):\n",
    "    model_.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    batch_times = []\n",
    "    total_inference_time = 0.\n",
    "    i = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in test_loader_:\n",
    "            if threshold is not None:\n",
    "                if i >= threshold:\n",
    "                    break\n",
    "\n",
    "            batch, labels = batch.to(device_), labels.to(device_)\n",
    "\n",
    "            batch_start = time()\n",
    "            outputs = model_(batch)\n",
    "            batch_time = time() - batch_start\n",
    "            batch_times.append(batch_time)\n",
    "            total_inference_time += batch_time\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if threshold is not None:\n",
    "                i += batch.shape[0]\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).mean()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    avg_batch_time = np.mean(batch_times) * 1000  # ms\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"avg_batch_time\": avg_batch_time,\n",
    "    }"
   ],
   "id": "d3265b8f7dcc1ff8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:51:16.536133Z",
     "start_time": "2025-05-11T07:51:16.532171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_result(cache):\n",
    "    print(f\"Accuracy: {np.mean(cache[\"accuracy\"]):.4f}\")\n",
    "    print(f\"Precision: {np.mean(cache[\"precision\"]):.4f}\")\n",
    "    print(f\"Recall: {np.mean(cache[\"recall\"]):.4f}\")\n",
    "    print(f\"F1-Score: {np.mean(cache[\"f1\"]):.4f}\")\n",
    "    print(f\"Average batch time: {np.mean(cache[\"avg_batch_time\"]):.4f} ms\")"
   ],
   "id": "eee37449e0870534",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:51:16.592631Z",
     "start_time": "2025-05-11T07:51:16.585746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_mean(model_, test_loader_, device_, num_iter):\n",
    "    cache = {\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"avg_batch_time\": []\n",
    "    }\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        temp = evaluate_model(model_, test_loader_, device_)\n",
    "        cache[\"accuracy\"].append(temp[\"accuracy\"])\n",
    "        cache[\"precision\"].append(temp[\"precision\"])\n",
    "        cache[\"recall\"].append(temp[\"recall\"])\n",
    "        cache[\"f1\"].append(temp[\"f1\"])\n",
    "        cache[\"avg_batch_time\"].append(temp[\"avg_batch_time\"])\n",
    "\n",
    "    # print(cache[\"avg_batch_time\"])\n",
    "    # print(sum(cache[\"avg_batch_time\"]))\n",
    "    # print(sum(cache[\"avg_batch_time\"]) / len(cache[\"avg_batch_time\"]))\n",
    "\n",
    "    print_result(cache)"
   ],
   "id": "66c50648c9672c4b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VGG16 GPU",
   "id": "9534d0b634883ab0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_path = \"/home/washindeiru/studia/sem_8/ssn/sem/pytorch-pruning/data/animals10/test\"",
   "id": "4b8a4eecbf1bf7b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:54:11.121944Z",
     "start_time": "2025-05-11T07:53:18.529434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = ModifiedVGG16Model()\n",
    "model.load_state_dict(torch.load(\"model_vg16_09_May_22:18.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "compute_mean(model, test_loader, device, 10)"
   ],
   "id": "f3314561481e2f2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9521\n",
      "Precision: 0.9531\n",
      "Recall: 0.9521\n",
      "F1-Score: 0.9522\n",
      "Average batch time: 1.0880 ms\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VGG16 pruned GPU",
   "id": "63a07462583feaf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:08:37.087228Z",
     "start_time": "2025-05-11T08:08:06.498425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = torch.load(\"model_vg16_prunned_10_May_14:55\", map_location=device, weights_only=False)\n",
    "model = model.to(device)\n",
    "\n",
    "compute_mean(model, test_loader, device, 10)"
   ],
   "id": "a51bf09dd4b743a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9343\n",
      "Precision: 0.9372\n",
      "Recall: 0.9343\n",
      "F1-Score: 0.9341\n",
      "Average batch time: 1.2586 ms\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VGG16 CPU",
   "id": "fe530933133ef42c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:52:55.015534Z",
     "start_time": "2025-05-11T07:52:41.531170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = ModifiedVGG16Model()\n",
    "model.load_state_dict(torch.load(\"model_vg16_09_May_22:18.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "result = evaluate_model(model, test_loader, device, 100)\n",
    "print_result(result)"
   ],
   "id": "e78bdb6586d075f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9688\n",
      "Precision: 0.9681\n",
      "Recall: 0.9658\n",
      "F1-Score: 0.9660\n",
      "Average batch time: 2877.3497 ms\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VGG16 pruned CPU",
   "id": "8a334c6e97434e27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:53:00.159958Z",
     "start_time": "2025-05-11T07:52:55.062798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = torch.load(\"model_vg16_prunned_10_May_14:55\", map_location=device, weights_only=False)\n",
    "result = evaluate_model(model, test_loader, device, 100)\n",
    "print_result(result)"
   ],
   "id": "7fe5ed20ccbeab6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9141\n",
      "Precision: 0.9269\n",
      "Recall: 0.9157\n",
      "F1-Score: 0.9166\n",
      "Average batch time: 1182.3679 ms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Liczba parametrów",
   "id": "7a95250056ecd868"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "VGG16",
   "id": "ae0c2b7a74bd6839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:07:06.990283Z",
     "start_time": "2025-05-11T08:07:05.021206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = ModifiedVGG16Model()\n",
    "model.load_state_dict(torch.load(\"model_vg16_09_May_22:18.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"VG16 łączna liczba parameterów: {total_params}\")\n",
    "\n",
    "total_conv_params = sum(p.numel() for p in model.features.parameters())\n",
    "print(f\"VG16 część konwolucyjna, liczba parameterów: {total_conv_params}\")\n",
    "\n",
    "total_class_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "print(f\"VG16 część klasyfikatora, liczba parameterów: {total_class_params}\")"
   ],
   "id": "66f995fe5ddf90a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VG16 łączna liczba parameterów: 134301514\n",
      "VG16 część konwolucyjna, liczba parameterów: 14714688\n",
      "VG16 część klasyfikatora, liczba parameterów: 119586826\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "VGG16 pruned",
   "id": "ca881e477b2feccb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:09:10.649360Z",
     "start_time": "2025-05-11T08:09:10.563347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = dataset.test_loader(test_path)\n",
    "model = torch.load(\"model_vg16_prunned_10_May_14:55\", map_location=device, weights_only=False)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params_pruned = sum(p.numel() for p in model.parameters())\n",
    "print(f\"VG16 łączna liczba parameterów: {total_params_pruned}\")\n",
    "\n",
    "total_conv_params_pruned = sum(p.numel() for p in model.features.parameters())\n",
    "print(f\"VG16 część konwolucyjna, liczba parameterów: {total_conv_params_pruned}\")\n",
    "\n",
    "total_class_params_pruned = sum(p.numel() for p in model.classifier.parameters())\n",
    "print(f\"VG16 część klasyfikatora, liczba parameterów: {total_class_params_pruned}\")"
   ],
   "id": "f18b3abd91589788",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VG16 łączna liczba parameterów: 38664702\n",
      "VG16 część konwolucyjna, liczba parameterów: 2169332\n",
      "VG16 część klasyfikatora, liczba parameterów: 36495370\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Model         | Łączna liczba parametrów     | Część konwolucyjna, liczba parametrów     | Część klasyfikatora, liczba parameterów     | Rozmiar pliku |\n",
    "|---------------|------------------------------|-------------------------------------------|---------------------------------------------|---------------|\n",
    "| VGG 16        | 134 301 514                  | 14 714 688                                | 119 586 826                                 | 537.2MB       |\n",
    "| VGG 16 pruned | 38 664 702                   | 2 169 332                                 | 36 495 370                                  | 154.7MB       |"
   ],
   "id": "f9c346db04a9a951"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Liczba usuniętych filtrów",
   "id": "8f3f954378bca1e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:30:38.504797Z",
     "start_time": "2025-05-11T08:30:38.500296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iter_1 = {21: 57, 17: 61, 28: 157, 26: 68, 14: 16, 19: 49, 12: 12, 24: 56, 5: 8, 10: 20, 7: 3, 2: 2, 0: 3}\n",
    "iter_2 = {28: 113, 12: 23, 21: 61, 26: 96, 17: 48, 19: 50, 24: 73, 0: 4, 14: 13, 10: 15, 7: 12, 5: 3, 2: 1}\n",
    "iter_3 = {17: 53, 24: 77, 12: 20, 21: 81, 19: 64, 26: 79, 28: 55, 14: 31, 10: 22, 5: 11, 7: 7, 2: 6, 0: 6}\n",
    "iter_4 = {7: 10, 17: 77, 19: 65, 10: 29, 2: 6, 28: 47, 26: 65, 21: 69, 24: 72, 12: 27, 14: 24, 0: 5, 5: 16}\n",
    "iter_5 = {7: 21, 14: 39, 24: 42, 2: 6, 19: 80, 17: 66, 12: 39, 5: 14, 21: 56, 26: 68, 0: 4, 10: 35, 28: 42}\n",
    "\n",
    "removed_filters = {}\n",
    "\n",
    "for temp in (iter_1, iter_2, iter_3, iter_4, iter_5):\n",
    "    for k,v in temp.items():\n",
    "        if k in removed_filters:\n",
    "            removed_filters[k] += v\n",
    "        else:\n",
    "            removed_filters[k] = v\n",
    "\n",
    "keys = sorted(removed_filters.keys())\n",
    "for key in keys:\n",
    "    print(f\"{key}: {removed_filters[key]}\")"
   ],
   "id": "55fb054718cab3fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 22\n",
      "2: 21\n",
      "5: 52\n",
      "7: 53\n",
      "10: 121\n",
      "12: 121\n",
      "14: 123\n",
      "17: 305\n",
      "19: 308\n",
      "21: 324\n",
      "24: 320\n",
      "26: 376\n",
      "28: 414\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| **Numer warstwy**             | 0  | 2  | 5  | 7  | 10  | 12  | 14  | 17  | 19  | 21  | 24  | 26  | 28  |\n",
    "|-------------------------------|----|----|----|----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| **Liczba usuniętych filtrów** | 22 | 21 | 52 | 53 | 121 | 121 | 123 | 305 | 308 | 324 | 320 | 376 | 414 |"
   ],
   "id": "8440187e021e6ea6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
